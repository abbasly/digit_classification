{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "MNIST Hand-written digit classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abbasly/digit_classification/blob/master/MNIST_Hand_written_digit_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvaSz17e2E3t"
      },
      "source": [
        "# MNIST Hand-written digit classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qURG6vJi2E3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4b9b5ed0-11a2-4b58-837e-420365658160"
      },
      "source": [
        "from __future__ import print_function\n",
        "from collections import namedtuple\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.python.training import moving_averages\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzJRprAY2E3z"
      },
      "source": [
        "## 1. Prepare the data\n",
        "### <a href=http://yann.lecun.com/exdb/mnist/>MNIST dataset</a>\n",
        "The MNIST has a training set of 55,000 examples, a validation set of 5,000 examples and a test set of 10,000 examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tvTOzg2E30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d04f0beb-e5d9-4ffb-9b21-209490352758"
      },
      "source": [
        "mnist = input_data.read_data_sets('./data/', one_hot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OABoBsq-2E32"
      },
      "source": [
        "Load the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKL3n9mK2E33"
      },
      "source": [
        "train_images = mnist.train.images[:1000]\n",
        "train_labels = mnist.train.labels[:1000]\n",
        "train_images = train_images.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxqrwE9U2E35"
      },
      "source": [
        "Load the validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UZ_-aQF2E36"
      },
      "source": [
        "val_images = mnist.validation.images\n",
        "val_labels = mnist.validation.labels\n",
        "val_images = val_images.reshape([-1, 28, 28, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSO5D74a2E39"
      },
      "source": [
        "Plot the 1st hand-written digit and its one-hot label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLNI7r_B2E3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "16ae5de6-f483-46a4-aa40-b2caebc66cb2"
      },
      "source": [
        "plt.imshow(train_images[0,:,:,0], cmap='Greys')\n",
        "print(\"\\nOne-hot labels for this image:\")\n",
        "print(train_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "One-hot labels for this image:\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1-2Y8ov2E3_"
      },
      "source": [
        "## 2. Build a graph for VGGNet (Oxford, 2014)\n",
        "Very Deep Convolutional Networks for Large-scale image recognition\n",
        "https://arxiv.org/abs/1409.1556\n",
        "\n",
        "<img src=\"img/fig2.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KolxK5HN2E4A"
      },
      "source": [
        "### Set hyperparameters\n",
        "- ***log_dir*** : Directory name to save models\n",
        "- ***n_epochs*** : Maximun training epoch\n",
        "- ***n_outputs*** : The number of classes for labels\n",
        "- ***init_lr*** : Learning rate for gradient descent\n",
        "- ***l2_lambda*** : regularization parameter\n",
        "- ***batch_size*** : The number of images to update paramerters once"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI35gp-B2E4B"
      },
      "source": [
        "log_dir = 'logs/'\n",
        "n_epochs = 20\n",
        "n_outputs = 10\n",
        "init_lr = 0.01\n",
        "batch_size = 100\n",
        "l2_lambda = 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTQJcwYC2E4E"
      },
      "source": [
        "### Placeholder for learning rate, input images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vy-F82m2E4E"
      },
      "source": [
        "lrn_rate = tf.placeholder(tf.float32, shape=(), name='lrn_rate')\n",
        "images = tf.placeholder(tf.float32, shape=(None, 28, 28, 1), name='images')\n",
        "labels = tf.placeholder(tf.int32, shape=(None), name='labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMoz36292E4G"
      },
      "source": [
        "def vggnet(images, labels=None):\n",
        "    vggnet_conv = partial(tf.layers.conv2d, kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_lambda), padding=\"SAME\")\n",
        "    \n",
        "    ''' 1st conv. '''\n",
        "    x1 = vggnet_conv(images, filters=16, kernel_size=7, strides=[1,1])  # 7x7 filter, # of filters: 16, stride: 1\n",
        "    x1 = tf.layers.batch_normalization(x1, name='bn1')                   # batch normalization\n",
        "    x1 = tf.nn.relu(x1)                                                  # ReLU activation\n",
        "    \n",
        "    ''' 2nd conv.'''\n",
        "    x2 = vggnet_conv(x1, filters=16, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 16, stride 1\n",
        "    x2 = tf.layers.batch_normalization(x2, name='bn2')                   # batch normalization\n",
        "    x2 = tf.nn.relu(x2)                                                  # ReLU activation\n",
        "    x2 = tf.layers.average_pooling2d(x2, pool_size=[2,2], strides=[2,2]) # 2x2 average pooling, stride: 2\n",
        "    \n",
        "    ''' 3rd conv. '''\n",
        "    a = vggnet_conv(x1, filters=16, kernel_size=3, strides=[2, 2])      # 3x3 filter, # of filters: 16, stride: 2\n",
        "    a = tf.layers.batch_normalization(a, name='bn3')                   # batch normalization\n",
        "    a = tf.nn.relu(a)                                                  # ReLU activation\n",
        "    \n",
        "    x3 = tf.math.add(a,x2)\n",
        "\n",
        "    x4 = x3\n",
        "\n",
        "    x5 = vggnet_conv(x3, filters=16, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 16, stride: 1\n",
        "    x5 = tf.layers.batch_normalization(x5, name='bn5')                   # batch normalization\n",
        "    x5 = tf.nn.relu(x5)                                                  # ReLU activation\n",
        " \n",
        "\n",
        "    x6 = tf.concat([x5, x4],3 )\n",
        "\n",
        "\n",
        "    ''' 6th conv. '''\n",
        "    x6 = vggnet_conv(x1, filters=32, kernel_size=3, strides=[1,1])       # 3x3 filter, # of filters: 32, stride: 1\n",
        "    x6 = tf.layers.batch_normalization(x6, name='bn6')                   # batch normalization\n",
        "    x6 = tf.nn.relu(x6)                                                  # ReLU activation\n",
        "    \n",
        "    img_feat = tf.reduce_mean(x6, [1, 2])                               # Global average pooling\n",
        "    return img_feat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WQb-xfm2E4I"
      },
      "source": [
        "### Build a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i66796F2E4J"
      },
      "source": [
        "global_step = tf.Variable(0, trainable=False)\n",
        "\n",
        "with tf.variable_scope('embed') as scope:\n",
        "#     feats = simple_network(images)\n",
        "    feats = vggnet(images)\n",
        "\n",
        "## Reshape\n",
        "feats = tf.reshape(feats, [batch_size, 32])\n",
        "    \n",
        "## Logits\n",
        "logits = tf.layers.dense(feats, n_outputs, kernel_initializer=tf.uniform_unit_scaling_initializer(factor=2.0), \n",
        "                                               kernel_regularizer=tf.contrib.layers.l2_regularizer(l2_lambda))\n",
        "\n",
        "## Evaluation\n",
        "correct = tf.nn.in_top_k(logits, labels, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "## SOFTMAX\n",
        "preds = tf.nn.softmax(logits)\n",
        "\n",
        "## Cost function\n",
        "cent = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels)\n",
        "cost_cls = tf.reduce_mean(cent, name='cent')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6UCnShc2E4L"
      },
      "source": [
        "### L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYiiiEh62E4L"
      },
      "source": [
        "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
        "cost = tf.add_n([cost_cls] + reg_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFUzAV9E2E4N"
      },
      "source": [
        "### Momentum optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q2MkWyZ2E4O"
      },
      "source": [
        "lr  = tf.train.exponential_decay(init_lr, global_step, 1000, 0.8, staircase = True) # learning rate decay\n",
        "optimizer = tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True)                  # Momentum optimizer\n",
        "train_op = optimizer.minimize(cost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTpr8qB42E4R"
      },
      "source": [
        "# 3. Train a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQOH6fT52E4S"
      },
      "source": [
        "### Create a session and initialize parameters\n",
        "Tensorflow operations must be executed in the session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wIiZN_W2E4S"
      },
      "source": [
        "## MAKE SESSION\n",
        "sess = tf.Session()\n",
        "\n",
        "## INITIALIZE SESSION\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoCz3nzo2E4U"
      },
      "source": [
        "### Updates parameters with back-propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGrALID42E4V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ffc6cdd9-14d5-4208-e65a-d4949ec9e788"
      },
      "source": [
        "for epoch in range(n_epochs+1):\n",
        "    for iteration in range(mnist.train.num_examples // batch_size):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "        X_batch = X_batch.reshape([-1, 28, 28, 1])\n",
        "        (_, loss, loss_cls, prediction) = sess.run([train_op, cost, cost_cls, preds], \n",
        "                                                    feed_dict={images: X_batch, labels: y_batch})\n",
        "        duration = time.time() - start_time\n",
        "        sec_per_batch = float(duration)\n",
        "    \n",
        "    ## Training accuracy every one epoch\n",
        "    acc_train = accuracy.eval(session=sess, feed_dict={images: X_batch, labels: np.argmax(y_batch, axis=1)})\n",
        "    if epoch % 1 == 0:\n",
        "        print('  [*] TRAINING Iteration %d, Loss: %.4f, Acc: %.4f (duration: %.3fs)'\n",
        "                             % (epoch, loss_cls, acc_train, sec_per_batch))\n",
        "\n",
        "    ## Validation accuracy every 5 epochs\n",
        "    if epoch % 5 == 0:\n",
        "        acc_val = accuracy.eval(session=sess, feed_dict={images: val_images, labels: np.argmax(val_labels, axis=1)})\n",
        "        print('  [*] VALIDATION ACC: %.3f' % acc_val)\n",
        "\n",
        "print('Optimization done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  [*] TRAINING Iteration 0, Loss: 1.8534, Acc: 0.3600 (duration: 0.161s)\n",
            "  [*] VALIDATION ACC: 0.258\n",
            "  [*] TRAINING Iteration 1, Loss: 1.5118, Acc: 0.5400 (duration: 0.168s)\n",
            "  [*] TRAINING Iteration 2, Loss: 0.7992, Acc: 0.7700 (duration: 0.165s)\n",
            "  [*] TRAINING Iteration 3, Loss: 0.3901, Acc: 0.8800 (duration: 0.164s)\n",
            "  [*] TRAINING Iteration 4, Loss: 0.4139, Acc: 0.8800 (duration: 0.164s)\n",
            "  [*] TRAINING Iteration 5, Loss: 0.2555, Acc: 0.9200 (duration: 0.167s)\n",
            "  [*] VALIDATION ACC: 0.912\n",
            "  [*] TRAINING Iteration 6, Loss: 0.5026, Acc: 0.8300 (duration: 0.166s)\n",
            "  [*] TRAINING Iteration 7, Loss: 0.2297, Acc: 0.9200 (duration: 0.165s)\n",
            "  [*] TRAINING Iteration 8, Loss: 0.1402, Acc: 0.9700 (duration: 0.167s)\n",
            "  [*] TRAINING Iteration 9, Loss: 0.2759, Acc: 0.9200 (duration: 0.163s)\n",
            "  [*] TRAINING Iteration 10, Loss: 0.3089, Acc: 0.9500 (duration: 0.166s)\n",
            "  [*] VALIDATION ACC: 0.949\n",
            "  [*] TRAINING Iteration 11, Loss: 0.1100, Acc: 0.9800 (duration: 0.163s)\n",
            "  [*] TRAINING Iteration 12, Loss: 0.1525, Acc: 0.9400 (duration: 0.167s)\n",
            "  [*] TRAINING Iteration 13, Loss: 0.2231, Acc: 0.9800 (duration: 0.165s)\n",
            "  [*] TRAINING Iteration 14, Loss: 0.0605, Acc: 0.9900 (duration: 0.167s)\n",
            "  [*] TRAINING Iteration 15, Loss: 0.1348, Acc: 0.9500 (duration: 0.163s)\n",
            "  [*] VALIDATION ACC: 0.963\n",
            "  [*] TRAINING Iteration 16, Loss: 0.1797, Acc: 0.9500 (duration: 0.164s)\n",
            "  [*] TRAINING Iteration 17, Loss: 0.1440, Acc: 0.9800 (duration: 0.168s)\n",
            "  [*] TRAINING Iteration 18, Loss: 0.1882, Acc: 0.9600 (duration: 0.166s)\n",
            "  [*] TRAINING Iteration 19, Loss: 0.1371, Acc: 0.9600 (duration: 0.167s)\n",
            "  [*] TRAINING Iteration 20, Loss: 0.0993, Acc: 0.9800 (duration: 0.164s)\n",
            "  [*] VALIDATION ACC: 0.965\n",
            "Optimization done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJWXl8vO2E4X"
      },
      "source": [
        "# 4. Test a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pUxJgKs2E4X"
      },
      "source": [
        "### Load the test images and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkKDWOpz2E4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "90beed14-fe67-47fd-f822-e4eb0aa7aa0d"
      },
      "source": [
        "## READ MNIST INPUTS\n",
        "test_images = mnist.test.images\n",
        "test_labels = mnist.test.labels\n",
        "test_images = test_images.reshape([-1, 28, 28, 1])\n",
        "\n",
        "## Plot the 1st test image and label\n",
        "plt.imshow(test_images[0,:,:,0], cmap='Greys')\n",
        "print(\"\\nOne-hot labels for this image:\")\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "One-hot labels for this image:\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk-RW7dP2E4a"
      },
      "source": [
        "### Check the prediction for the first image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHaFXQVg2E4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6b107fa-beb6-497b-e51c-0886d0670929"
      },
      "source": [
        "prediction = sess.run(preds, feed_dict={images: test_images[0,:,:,0].reshape(1,28,28,1), labels: test_labels[0]})\n",
        "\n",
        "print(\"The prediction of the network is: %d\" % np.argmax(prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction of the network is: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL-j_ndn2E4d"
      },
      "source": [
        "### Average the accuray for test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZPVcFfB2E4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2b00faf-654d-436a-e7b0-b77cc3c71492"
      },
      "source": [
        "test_acc = accuracy.eval(session=sess, feed_dict={images: test_images, labels: np.argmax(test_labels, axis=1)})\n",
        "print('Acc: %.3f' % test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.966\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}